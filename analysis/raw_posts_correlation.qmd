```{python}
#| label: imports
#| echo: false
#| output: false
from google.oauth2 import service_account
import pandas as pd
import matplotlib.pyplot as plt
import pandas_gbq
import sys
import os
sys.path.append(os.path.abspath("../"))
from analysis.bq_queries import get_post_count_ili_sql, get_llm_ili_sql
from analysis.feature_eng import *
from analysis.model_evaluation import *
credentials = service_account.Credentials.from_service_account_file(
    '../.gc_creds/digepizcde-71333237bf40.json')
```

```{python}
#| label: sql_raw_post counts
#| output: false

who_subset = 'flunet'
lang = 'fr'#'fr'
country_code = 'FRA' #"FRA"

ili_kws = [
    'grippe',  'rhume', 'fievre', 'courbature'
    # "Grippe", 'grippe', 'Schnupfen', 'Fieber', 'Muskelschmerzen'
]
ili_kws_sql = [f"'{x}'" for x in ili_kws]
```

```{python}
control_kws = ['travail', 'voiture', 'demain', 'sommeil']
# control_kws = ['Auto', 'morgen', 'Arbeit', 'arbeiten', 'schlafen', 'Schlaf']
control_kws_sql = [f"'{x}'" for x in control_kws]
```

```{python}
post_count_ili_sql ="SELECT * FROM `digepizcde.bsky_ili.bsky_ili_fr`"
```

```{python}
#| echo: false
#| output: false
post_count_ili_df = pandas_gbq.read_gbq(
   post_count_ili_sql, credentials=credentials
).set_index('date')
post_count_ili_df.index = pd.to_datetime(post_count_ili_df.index)
```


```{python}
post_count_ili_df['year'] = post_count_ili_df.index.year.astype("category")
post_count_ili_df['month'] = post_count_ili_df.index.month.astype("category")
post_count_ili_df['week'] = post_count_ili_df.index.isocalendar().week.astype("category")
post_count_ili_df['season'] = post_count_ili_df['month'].apply(assign_season).astype("category")
```

```{python}
lags = 2
weeks_ahead = 1
X = post_count_ili_df.drop([
    'ili_case', 'ari_case', 'ili_incidence', 'ari_incidence',
    'ili_pop_cov', 'ari_pop_cov', 'rest_posts', 'grippe_posts'
    ], axis = 1)
lagdfs = []

for l in range(1, lags+1):
    lagdf = X.shift(l)
    lagdf.columns = [f"{c}_lag{l}" for c in lagdf.columns]
    lagdfs.append(lagdf)

X = pd.concat([X, *lagdfs], axis = 1).dropna().iloc[:-weeks_ahead,:]
```

```{python}
y = post_count_ili_df['ili_incidence'].iloc[lags+weeks_ahead:]
y = y.divide(y.max())
```

```{python}
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import cross_validate
from sklearn.pipeline import make_pipeline
```

```{python}
ts_cv = TimeSeriesSplit(
    n_splits=5,
    gap=0,
    max_train_size=100,
    test_size=10,
)
```

```{python}
gbrt = HistGradientBoostingRegressor(categorical_features="from_dtype", random_state=42)
categorical_columns = X.columns[X.dtypes == "category"]
print("Categorical features:", categorical_columns.tolist())
```

```{python}
evaluate(gbrt, X, y, cv=ts_cv, model_prop="n_iter_")
gbrt.fit(X, y)
```

```{python}
ypred = pd.Series(gbrt.predict(X), index = y.index) 
```

```{python}
y.plot(label = 'True incidence')
ypred.plot()
```

```{python}
from sklearn.inspection import permutation_importance

result = permutation_importance(
    gbrt, X, y, n_repeats=50, random_state=42, n_jobs=-1
)

sorted_importances_idx = result.importances_mean.argsort()
importances = pd.DataFrame(
    result.importances[sorted_importances_idx].T,
    columns=X.columns[sorted_importances_idx],
).iloc[:,-5:]
ax = importances.plot.box(vert=False, whis=10)
ax.set_title("Permutation Importances")
ax.axvline(x=0, color="k", linestyle="--")
ax.set_xlabel("Decrease in accuracy score")
ax.figure.tight_layout()
```

```{python}
month_splines = periodic_spline_transformer(12,6) \
    .fit_transform(post_count_ili_df[['month']])

# Create a dataframe for the splines
month_splines_df = pd.DataFrame(
    month_splines, 
    index=post_count_ili_df.index,
     columns=[f'month_spline_{i}' for i in range(month_splines.shape[1])])

# Concatenate the splines with the original dataframe
post_count_ili_df = pd.concat([post_count_ili_df, month_splines_df], axis=1)
```

```{python}
week_splines = periodic_spline_transformer(54, 27) \
    .fit_transform(post_count_ili_df[['week']])

# Create a dataframe for the splines
week_splines_df = pd.DataFrame(
    week_splines, 
    index=post_count_ili_df.index,
     columns=[f'week_spline_{i}' for i in range(week_splines.shape[1])])

# Concatenate the splines with the original dataframe
post_count_ili_df = pd.concat([post_count_ili_df, week_splines_df], axis=1)
```


```{python}
llm_ili_sql = get_llm_ili_sql(
    ili_kws, lang, country_code
)
```

```{python}
#| echo: false
#| output: false
llm_ili_df = pandas_gbq.read_gbq(
    llm_ili_sql, credentials=credentials 
).set_index('date')
llm_ili_df.index = pd.to_datetime(llm_ili_df.index)
```
